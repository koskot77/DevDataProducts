require(tm)
tw <- read.csv(file="uk.csv",header=T,sep=',')
tw$Text <- sub("@\\w+","",tw$Text,perl = TRUE)
tw$Text <- sub("(:\\w+:)+","",tw$Text,perl = TRUE)
tw$Text <- sub("http[^\\s]*","",tw$Text,perl = TRUE)
corp <- Corpus(VectorSource(tw$Text),readerControl = list(language = "rus"))
corp <- tm_map(corp, stripWhitespace)
corp <- tm_map(corp, removePunctuation)
corp <- tm_map(corp, content_transformer(tolower))
corp <- tm_map(corp, removeWords, stopwords("russian"))
corp <- tm_map(corp, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corp, control = list( weighting = function(x) weightTfIdf(x,normalize = FALSE), stopwords = TRUE) )
dtmLight <- removeSparseTerms(dtm, 0.999)
require(proxy)
d <- dist(as.matrix(dtmLight[1:1000,]), method = "cosine")
hc <- hclust(d)
dend = as.dendrogram(hc)
plot(dend)

#inspect(dtmLight[3, which(as.vector(dtmLight[3,])*as.vector(dtmLight[60,])!=0)] )
#as.matrix(d)[3,60]
#writeLines(as.character(corp[[3]]))
#writeLines(as.character(corp[[60]]))
#writeLines(as.character(corp[[48]]))
#table( as.factor( cutree(hc, 100) ) )
#findAssocs(dtm, "make", 0.1)
#findFreqTerms(dtm, 5000)
